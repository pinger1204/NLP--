## 完整语料库的预处理

对单个句子进行预处理有所了解后，可以编写完整处理gutenberg语料库的预处理代码。

这里需要提到，之后会对Mass等人整理的电影评论语料库进行处理，所以这里借鉴他们不采用停用词和词干提取，因为停用词是“情感的象征”，这对电影评论情感分析来说是至关重要的。

在确定好预处理步骤后，开始对gutenberg语料库进行预处理：

```python
#大写字母转换及标点符号删除
lower_sents = []
for s in gberg_sents:
      lower_sents.append([w.lower() for w in s if w.lower()
                          not in list(string.punctuation)])
#重新检测二元分词搭配
lower_bigram = Phraser(Phrases(lower_sents))
```

从一个空列表lower_sents开始，使用for循环将预处理语句加到该列表上。去掉标点符号和大写字母后，重新开始在整个语料库中检测二元分词搭配，根据之前在处理n-gram中提到的方法，在这一行代码中创建了lower_bigram对象，代码如上所示。查看一部分的输出结果如下：

![完整预处理](https://github.com/pinger1204/NLP--/blob/master/image/%E5%AE%8C%E6%95%B4%E9%A2%84%E5%A4%84%E7%90%86.png)

观察输出结果，发现计数（得分）默认的最小阈值有些宽松，例如，对于two daughter和her sister这样的，不应该被认为二元分词。所以接下来对阈值进行调整，Phrases（）参数设置最小计数阈值为32，最小得分阈值为64。

```python
lower_bigram = Phraser(Phrases(lower_sents,
                                min_count=32, threshold=64))
```

可以调用 lower_bigram.phrasegrams 对调整完的结果进行查看。针对调整完阈值的lower_bigram对象，可以用for循环迭代地添加一个预处理好语句的语料库：

```python
#创建一个包含二元分词的“干净”语料库
clean_sents = []
for s in lower_sents:
      clean_sents.append(lower_bigram[s])
```

到这里，完整语料库已经经过了预处理，可以对其包含的元素进行查看。例如，若要查看1到8个元素，则调用代码  clean_sents[0:9]  ；若要展示第7个元素，则调用代码  clean_sents [6] 。