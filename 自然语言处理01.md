# 自然语言处理01

## 简介

自然语言处理，即Natural Language Processing，简写为NPL。

NLP可以分为“自然语言”和“处理”两部分。自然语言，区别于计算机语言，包括口语及书面语。而处理则指计算机处理。

## 发展历程

1948年，香农提出信息熵的概念，熵是NLP的基石之一，此时尚未有NLP。

1949年，美国人威弗首先提出了机器翻译设计方案。

NLP发源于1950年，图灵在这一年提出“图灵测试”，一般被认为是自然语言处理思想的开端。

1950-1970年，模拟人类学习语言的习惯，以语法规则为主流。

1970年开始，统计学派盛行，NLP转向统计方法，以具有马尔科夫性质的模型为核心。

2001年，神经网络与语言模型相结合，这应该是第一次用神经网络得到词嵌入矩阵，证明了神经网络构建语言模型的可能性。

2003年，LDA模型提出，概率图模型受到关注。

20世纪80、90年代，卷积神经网络、循环神经网络等已经被提出，但受限于计算能力，大多停留在理论阶段。

2008年以后，深度学习被逐渐引入自然语言处理。2013年，NLP的里程碑式技术word2vec提出。随着神经网络的计算不再受限，NLP的深度学习时代开启。2014年，seq2seq提出。2015年，NLP的另一个里程碑attention提出。

## NLP基本分类

根据NLP的最终目标，大致可以分为自然语言理解和自然语言生成两种。

自然语言理解侧重于如何理解文本，包括文本分类、命名实体识别、指代消歧、机器阅读理解等。

自然语言生成侧重于理解文本如何生成自然文本，包括自动摘要、机器翻译、问答系统、对话机器人等。

所以NLP的基本领域为：文本检索、机器翻译、**文本分类/情感分析**、信息抽取、序列标注、文本摘要、问答系统、知识图谱、文本聚类。

## 研究难点

现如今还有很多限制NLP发展的因素，并且大多数上是基础技术的难点。例如在中文上分词表现不好；很多单词不止一个意思，词义消歧就比较困难；二义性：有些句子通常有多种理解方式，另外在文本相似度计算和文本生成的评价指标上也存在一定难度。





参考资料来源：https://www.zhihu.com/topic/19560026/intro

[https://baike.baidu.com/item/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/365730?fr=aladdin#2](https://baike.baidu.com/item/自然语言处理/365730?fr=aladdin#2)