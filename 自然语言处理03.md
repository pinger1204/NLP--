# 分词

接之前，在对语料库进行建模之前，首先需要进行自然语言预处理。今天主要提到的是预处理的一个步骤：分词。

在介绍分词之前，首先提一下在接下来的预处理步骤的实现中，用到的语料库是gutenberg，它是一个小型英文语料库，由18部文学作品组成。

分词（tokenization）指将文档拆成离散的字词单位（token），对于英文来说，单词之间有空格隔开，但对于中文，分词是必要进行的预处理步骤。

##### （注意：在开始一下代码运行前，必须先运行自然语言处理02

[]: https://github.com/pinger1204/NLP-01/blob/master/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%8602.md

##### 中的代码，并确定语料库及工具包安装正确！！）

接下来依据语料库gutenberg进行分词处理，代码及运行结果：

```python
from nltk.corpus import gutenberg  #加载语料库gutenberg
```

加载语料库后，对语料库进行大致了解，查看文档个数和文档名称等基本信息：

```python
len(gutenberg.fileids())  #查看语料库的文档个数
```

显然，这行代码运行的结果是18，语料库由18个文档组成。然后查看所包含文档的名称：

```python
gutenberg.fileids()  #语料库gutenberg所包含的文档名称
```

![文档名称](https://github.com/pinger1204/NLP-01/blob/master/image/text%20name.png)

```python
len(gutenberg.words())  #查看语料库包含的单词量，即单词的个数
```

该行代码输出的结果为2621613，即语料库中共有2621613个单词。

对用到的语料库有了大致了解后，开始进行分词/断句处理，就用到了之前已经下载好的nltk_data文件中的工具包punkt，所以进行该步骤时，**一定要将punkt解压，并在解压的文件中新建名为PY3的文件夹，将解压内容中的 english 放入PY3文件夹中**。

具体的分词过程代码如下：

```python
gberg_sent_tokens=sent_tokenize(gutenberg.raw())  #将语料库变为句子列表
gberg_sent_tokens[0:6]  #访问输出列表的前6个
```

![输出列表前6个](https://github.com/pinger1204/NLP-01/blob/master/image/%E5%88%86%E8%AF%8D%E5%89%8D6%E4%B8%AA%E5%8F%A5%E5%AD%90%E5%88%97%E8%A1%A8.png)

```python
gberg_sent_tokens[1]  #查看列表中的第2个句子
```

![第2个句子](https://github.com/pinger1204/NLP-01/blob/master/image/%E7%AC%AC2%E4%B8%AA%E5%8F%A5%E5%AD%90.png)

```python
word_tokenize(gberg_sent_tokens[1])  #将第2个句子分解到单词级别，并且删除所有空格和换行符
```

![](https://github.com/pinger1204/NLP-01/blob/master/image/%E7%AC%AC2%E4%B8%AA%E5%8F%A5%E5%AD%90%20%E5%8D%95%E8%AF%8D.png)

```python
word_tokenize(gberg_sent_tokens[1])[14]  #查看第2个句子中的第15个单词
```

该行代码查看分解到单词级别的第2个句子的第15个单词，输出结果为：father。

以上代码已经实现了将文档的句子进行分词的步骤，上述采用的是sent_tokenize()和word_tokenize()方法，而下面则使用gutenberg语料库中内置的方法：sends()，进行相同的处理。

```python
gberg_sents=gutenberg.sents()
gberg_sents[0:6]  #生成分词列表
gberg_sents[4][14]  #第2个句子现在是第5个元素，查看它的第15个单词
```

![分词列表](https://github.com/pinger1204/NLP-01/blob/master/image/%E5%88%86%E8%AF%8D%E5%88%97%E8%A1%A8.png)

上述代码生成分词列表，图中显示结果为一部分，可以发现，sends()方法还将标题页和章节标记分隔为单独的元素，所以第一个句子现在是第2个元素，即如果仍然查看第二个句子的第15个单词，则如上述代码，是第5个元素的第15个单词，显然，输出结果仍是：father。

这就是对一个句子进行分词预处理的操作过程。